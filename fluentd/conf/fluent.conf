# Enhanced Fluentd configuration for Brick Check Pipeline
# This configuration aggregates logs locally AND forwards to Google Cloud Logging

<system>
  log_level info
</system>

# Install required gems for Google Cloud
<source>
  @type exec
  command echo "Installing fluent-plugin-google-cloud..."
  run_interval 86400
  tag install.google_cloud_plugin
</source>

# Input from Docker containers
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Input from application log files
<source>
  @type tail
  @id input_pipeline_logs
  path /var/log/brick-check/pipeline_*.log
  pos_file /var/log/fluentd-pipeline.log.pos
  tag brick.pipeline
  <parse>
    @type regexp
    expression /^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (?<message>.*)$/
    time_key timestamp
    time_format %Y-%m-%d %H:%M:%S
  </parse>
</source>

<source>
  @type tail
  @id input_error_logs
  path /var/log/brick-check/errors.log
  pos_file /var/log/fluentd-errors.log.pos
  tag brick.error
  <parse>
    @type regexp
    expression /^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) ERROR: (?<message>.*)$/
    time_key timestamp
    time_format %Y-%m-%d %H:%M:%S
  </parse>
</source>

<source>
  @type tail
  @id input_stage_logs
  path /var/log/brick-check/stages.log
  pos_file /var/log/fluentd-stages.log.pos
  tag brick.stage
  <parse>
    @type regexp
    expression /^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) STAGE: (?<message>.*)$/
    time_key timestamp
    time_format %Y-%m-%d %H:%M:%S
  </parse>
</source>

# Filter to add metadata for both local and cloud logging
<filter brick.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    environment gcloud_vm
    application brick-check
    version 1.0.0
    project_id "#{ENV['GOOGLE_CLOUD_PROJECT'] || 'unknown'}"
    vm_instance "#{ENV['HOSTNAME'] || 'unknown'}"
    component "${tag_parts[1]}"
    severity "${tag_parts[1] == 'error' ? 'ERROR' : tag_parts[1] == 'stage' ? 'NOTICE' : 'INFO'}"
    log_source "fluentd-local"
  </record>
</filter>

# Output to multiple destinations
<match brick.**>
  @type copy
  
  # Output to console for debugging
  <store>
    @type stdout
    <format>
      @type json
      time_format %Y-%m-%d %H:%M:%S
    </format>
  </store>
  
  # Output to local file with rotation
  <store>
    @type file
    path /var/log/brick-check/aggregated/brick-check
    append true
    <format>
      @type json
      time_format %Y-%m-%d %H:%M:%S
    </format>
    <buffer time>
      timekey 1h
      timekey_wait 10m
      flush_mode interval
      flush_interval 30s
    </buffer>
  </store>
  
  # Output to syslog for system integration
  <store>
    @type syslog
    host localhost
    port 514
    facility local0
    severity info
    tag brick-check
  </store>
  
  # Forward to Google Cloud Logging (if configured)
  <store>
    @type google_cloud
    @id output_gcp_brick_check_fluentd
    
    # Use metadata service authentication
    use_metadata_service true
    
    # Log configuration
    log_name "brick-check-fluentd"
    
    # Resource configuration
    <labels>
      application "brick-check"
      environment "production"
      component "fluentd"
      vm_instance "#{ENV['HOSTNAME'] || 'unknown'}"
    </labels>
    
    # Buffer configuration
    <buffer>
      @type memory
      flush_mode interval
      flush_interval 15s
      chunk_limit_size 1MB
      retry_forever false
      retry_max_times 3
      retry_wait 5
    </buffer>
    
    # Format configuration
    <format>
      @type json
    </format>
  </store>
</match>

# Catch-all for other logs
<match **>
  @type copy
  
  <store>
    @type stdout
    <format>
      @type json
      time_format %Y-%m-%d %H:%M:%S
    </format>
  </store>
  
  # Also send other logs to Cloud Logging
  <store>
    @type google_cloud
    @id output_gcp_other
    use_metadata_service true
    log_name "brick-check-system"
    
    <labels>
      application "brick-check"
      environment "production"
      component "system"
    </labels>
    
    <buffer>
      @type memory
      flush_mode interval
      flush_interval 30s
      retry_forever false
      retry_max_times 2
    </buffer>
  </store>
</match> 